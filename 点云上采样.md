# 点云上采样/生成

## Tips

​	梯度消失解决：使用BatchNorm，将激活函数换为ReLu，使用Xaiver初始化等



## PointCloud Upsampling

上采样的三个关键点：

1. 要处理点云**无序、无拓扑**的结构
2. 生成的点应该具备**特征信息**，应**描述**潜在目标对象的基础**几何形状**，这意味着它们应大致位于目标对象表面上。（不应在内部）
3. 生成的点**不应杂乱无章**，生成的输出点集在目标对象表面上应该更加**均匀**。



### CVPR2018_PU-Net

​	The key idea is to learn multi-level features per point and expand the point set via **a multi branch convolution unit** implicitly in feature space.  核心思想是学习每个点的多层次特征，然后利用隐含在特征空间中的不同卷积分支进行扩充， 

​	 The expanded feature is then split to a multitude of features, which are then reconstructed to an upsampled point set. 扩展的特征会分解为多个特征，然后将其重构为上采样点集。



流程**patch** extraction --> point feature embedding  --> feature expansion --> coordinate reconstruction

首先，从给定的一组先验3D模型中提取具有不同尺度和分布的**点块**

​	然后，点特征集成组件通过**分层特征学习**和**多级特征聚合**将原始3D坐标映射到特征空间。

​	之后，我们使用特征扩展组件**扩展特征的数量**

​	并通过坐标重建组件中的一系列全连接层重建输出点云的3D坐标。

![1603181094050](./assets/1603181094050.png)



**1. patch extraction**

​	随机选择这些物体表面上的 $M$ 个点。从每个选定的点开始，我们在物体上生成一个曲面块，该块上的任何点与曲面上的选定点的距离都 **小于** 给定的测地线**距离**（$d$）。 然后，我们使用 Poisson 盘采样在每个块上随机生成 $N$ 个点，作为块上的参考 G.T. 分布。 在我们的上采样任务中，局部和全局上下文都有助于平稳而均匀的输出。 因此，我们用不同的大小设置 $d$ ，以便我们可以以**不同的尺度和密度**提取先前物体上的点块。



**2. point feature embedding**

​	为了从块中学习**局部和全局**几何背景，我们考虑以下两种特征学习策略，它们的优势是相辅相成的：

- Hierarchical feature learning 层次特征学习

​	**渐进地捕获越来越多的层次结构特征已被证明是提取局部和全局特征的有效策略**。 因此，采用PointNet++ [30]中提出的分层特征学习机制。 

​	具体在每个级别使用相对较小的分组半径，因为生成新点通常比[30]中的高级识别任务涉及更多的局部上下文。

- Multi-level feature aggregation 多级特征聚合

​	直接组合不同级别的特征，并让网络了解每个级别的重要性

​	由于在每个 patch 上设置的输入点在层次特征提取中逐步进行了二次采样，因此我们首先通过PointNet++中的插值方法从下采样后的点特征中恢复所有原始点的特征，从而将每个级别的点特征连接起来。



**3. feature expansion**

​	我们扩展了特征空间中的特征数量，这相当于扩展点的数量，因为点和特征是可以互换的。

​	假设 $f$ 维数是 $N×\hat{C}$，$N$ 是输入点的数目，$\hat{C}$ 是级联集成特征的特征维数。特征扩展操作将输出维数为 $rN×\hat{C}_2$ 的特征 $f'$，其中 $r$ 是上采样率，$\hat{C}_2$ 是新的特征维数。
$$
f^{\prime}=\mathcal{R S}\left(\left[\mathcal{C}_{1}^{2}\left(\mathcal{C}_{1}^{1}(f)\right), \ldots, \mathcal{C}_{r}^{2}\left(\mathcal{C}_{r}^{1}(f)\right)\right]\right)
$$
​	其中 $\mathcal{C}_{i}^{1}(\cdot)$ 和 $\mathcal{C}_{i}^{2}(\cdot)$ 是两组分开的 $1\times1$ 卷积。$\mathcal{R S}(\cdot)$ 是Reshape的操作，将张量尺寸由 $N\times r\hat{C}_2$ 转换为 $rN\times \hat{C}_2$。

​	从每个集合中的第一卷积  $\mathcal{C}_{i}^{1}(\cdot)$ 生成的 $r$ 个特征集合具有高相关性，这将导致最终重建的3D点彼此过于接近。因此，我们进一步为每个特征集添加另一个卷积 $\mathcal{C}_{i}^{2}(\cdot)$ (具有单独的权重)。



**4. coordinate reconstruction**

​	全连接 将特征回归成坐标



**5. 损失函数：**

Reconstruction loss ：将点放置在的物体下表面上，使预测点云与参考G.T.点云相似

Replusion loss ：为了更均匀地分布生成的点，避免生成的点倾向于位于原始点附近。







---

### CVPR2019_3PU: Patch-based progressive 3D point set upsampling

1次16x上采样 分为4次2x上采样  `2*2*2*2`

![1614578310673](assets/1614578310673.png)



**1. 多步基于patch的感受野**

目的：**理想的网络，需要自适应的调整感受野从而在不同尺度中把握对应的细节信息进一步学习几何特征** 

问题：不规则，没有拓扑结构，点云集上应用多范围感受野不现实。邻居信息必须通过KNN算法，每层每点都这样计算一遍代价太大

解决方法：patch的size应自适应于感受野的范围。通常来讲感受野范围由KNN大小来定。所以，如果邻域大小被固定，随着点集越来越密集，感受野就会变窄，当感受野相对比较窄时，网络就不用处理所有的点。网络递归地上采样点集，并同时减少空间跨度。



**2. 多步端到端训练**

目的： 空间尺度不断减小，由全局逐渐聚焦局部；加快网络训练

解决方法：在 $U_{\hat{L}}$ 的第一阶段，我们固定单元 $U_1$ 到 $U_{\hat{L}-1}$ 的网络参数，并开始训练 $U_{\hat{L}}$。在第二阶段，我们释放固定的单元并同时训练所有单元，即 $U_1$ 到 $U_{\hat{L}}$ 。这种训练方法可以避免新单元出现梯度扰乱而影响到先前单元的稳定性。由于第一个单元没有前置训练，因此 $U_1$ 只需要训练一次，总共需要 $2^L-1$ 次训练。由于感受野内的点数固定，因此随着级数的增加宏观角度来看所处理的空间尺度也在收窄，聚焦的尺度也从全局逐渐转变为细节的特征学习。

![1614599768055](assets/1614599768055.png)



**3. Upsampling network unit 上采样网络单元** 

- **通过层内密集连接进行特征提取**

通过第一层mlp提取特征$C'$，然后通过**knn对特征进行分组**，分组后再次经过第二层MLP提取特征$G$，然后残差连接加上输入$G+C'$

**残差连接**是利用跨网络不同层提取的特征的强大工具

然后再次通过第三层mlp，再次残差连接 $G+G+C'$

最大池化保证序列不变性，降维，在加上最开始的输入坐标 $G+G+C'+d$

通过过渡层压缩为 $C’$ ,输入到下一层重复提取特征



一个白色的为一个denseblock，在denseblock之间使用了残差连接

![1614599963260](assets/1614599963260.png)



- **通过代码分配特征扩展**

为每个重复的特征分配一个值-1和1的一维代码**，**以将它们转换到不同的位置  **产生位置扰动**（类似FoldingNet）

接下来，使用一组MLP将特征 $2N×（C +  1）$压缩为 $2N×d$ 的残差特征，我们将其添加到**初始输入坐标**以生成输出点。

![1614599899000](assets/1614599899000.png)



- **通过双边特征插值进行层间残差连接**

引入了**层间残差连接**以增强**上采样单元之间的通信**，这充当了使用不同感受野范围提取的特征的桥梁

注意是**特征**之间的连接，在**特征提取模块之后**，**特征扩展模块之前**，由于**维度不一致**，需要先进行**插值**

![1614599768055](assets/1614599768055.png)



**4. loss function** 

​	改进的CD Chamfer distance







------

### ICCV2019_PU-GAN

流程与PU-Net相似 

![img](assets/li2-480300h202-large.gif)

​	总体分为生成器和鉴别器



生成器包括 

**特征提取模块 ** 从输入点云 $\mathcal{P}$ 中提取特征 使用**3PU**中的方法

**特征扩展模块 ** 将特征 $F$ 通过Up模块变为 $F_{up}$ ，

**点集生成模块** 从 $F_{up}$ 回归成坐标，然后再进行FPS下采样，保留需要的点数。





鉴别器 

​	首先提取全局特征，然后将局部特征与全局特征联结起来；特征串联后，通过自注意力机制单元增强特征学习/增强特征集成/之前后续特征提取能力；再次通过mlp+maxpooling 获取全局特征。然后将特征通过全连接层回归成置信度值。判断生成器输出的真假



两个模块

- 生成器-特征扩展-up-down-up unit





- 鉴别器-self-attention unit









---

### Data-driven upsampling of point clouds.















---

## PointCloud Completion

### CVPR2020_SA-Net: Point Cloud Completion by Skip-attention Network with Hierarchical Folding

















---

## PointCloud Generation

### CVPR2018_FoldingNet

> folding : 将复制codeword的连接称为低维**网格点**，然后将**point-wise MLP** 每个点都经过MLP称为**folding**操作。 

![1614604444799](assets/1614604444799.png)



Encoder 基于graph 最近邻 maxpooling 组合局部形状信息特征

Decoder 基于folding  学习一种"力"将2D网格折叠扭曲成3D点云形状   比基于折叠的反卷积效果好

两个连续的folding操作：第一个将2D网格折叠到3D空间，第二个在3D空间内部折叠



AE架构具有interpretable可解释性



---

### Atlas-Net















---

## PointCloud Consolidation

---

### ECCV2018_EC-Net：an Edge-aware Point set Consolidation Network

![1614755669724](assets/1614755669724.png)

**Fig. 2: The pipeline of EC-Net.**  对于输入**patch**中的每个点，我们首先使用PointNet++将其局部几何编码为特征向量 $f$（大小：$N×D$），然后使用特征扩展机制将 $f$ 扩展为 $f'$（大小：$rN×D_2$）。然后，我们对**残差点坐标**以及**距扩展特征的点到边距离**（$d$）进行回归，并通过将原始点坐标添加到残差来形成输出点坐标。最后，网络识别边缘上的点并产生输出点。该网络使用边缘感知的联合损失功能进行了训练，右侧四个黄色框。



​	基于 edge-aware 技术，具有边缘感知能力

​	制定回归分量 从上采样的特征中同时恢复 **点坐标** 和 **点到边的距离**

​	边感知 联合损失函数 最小化输入点到3D曲面和边的距离

​	可以关注检测到**尖锐边缘**并实现更准确的3D重建，它可以识别边缘点并沿着边缘（以及整个表面）生成更多点，从而有助于保留清晰特征的3D重建。



​	受PointNet的启发，我们通过将3D点的**坐标转换为深层特征**并通过**特征扩展**产生更多点来直接处理3D点。

​	

​	提取**patch** 以使同patch中的点在基本表面上大致接近

​	将一个点视为node 通过knn构造加权图，边权重为欧氏距离

​	随机选择m=100个点作为patch的质心；从每个选定的点开始，使用Dijkstra算法根据图中的最短路径距离找到2048个最近的点。随机在其中选择1024个点



**Feature embedding and expansion.** 

​	使用pointnet++提取1024个（即1patch）的特征N，保留一半的特征为 $f$ 之后使用PU-NET中的特征扩展模块进行参数扩展。

**Edge distance regression.** 

​	每个扩展特征（等价于一个 **点**）回归一个点到边的距离，以进行**边缘点识别**。 回归距离是与该patch相关联的所有**带注释边缘段**中从输出点到最近的**带注释边缘段**的最短估计距离。

​	通过一个全连接的层从扩展特征 $f’$ 提取距离特征 $f_{dist}$，然后通过另一个全连接的层从 $f_{dist}$ **回归**成点到边缘的距离 $d$。 我们分两步进行操作，这样我们就可以将 $f_{dist}$ 也输入坐标回归组件。

**Coordinate regression.** 

扩展特征 $f’$ 与距离特征 $f_{dist}$ （来自上一个组件）连接起来输入全连接层来回归成点坐标

**Edge points identiﬁcation.** 

将 $d_i$ 表示为输出点 $x_i$ 的点到边的回归距离，接下来我们找到一个输出点的子集，即边缘附近的边缘点（用阈值 $\Delta_d$ 表示为 $S_{\Delta_d}$）：$\mathcal{S}_{\Delta_{d}}=\left\{x_{i}\right\}_{d_{i}<\Delta_{d}}$。 请注意，此组件在训练和推理阶段均执行。



![1614758934785](assets/1614758934785.png)

– In the edge distance regression component, we ﬁrst use one fully-connected layer with width 64 to regress fdist from f0. Then, we use another fully-connected layer with width 1 to regress the point-to-edge distance d. 在边缘距离回归组件中，我们首先使用一层宽度为64的全连接的层**使 $f_{dist}$ 从 $f'$ 回归**。 然后，我们使用另一个宽度为1的全连接的层来回归点到边的距离 $d$ 。



4个loss 

**Surface loss** 促使输出点位于下层曲面附近

**Edge loss** 促使输出点具有边缘感知，即位于边缘附近

**Repulsion loss** 鼓励输出点在基础表面上更均匀地分布

**Edge distance regression loss **指导网络将点到边缘距离 $d$ 回归为 $rN$ 个输出点



用来满足： （i）靠近底层的对象表面，（ii）边缘感知（位于靠近带注释的边缘）（iii）更均匀地分布在对象表面上。



**End-to-end training**







---

## PointCloud Learning Representations

### ICLR-W2018_Learning representations and generative models for 3D point clouds. 

latent_3d_points阅读



