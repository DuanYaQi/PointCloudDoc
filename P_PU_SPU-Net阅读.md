# SPU-Net

Self-Supervised Point Cloud Upsampling by Coarse-to-Fine Reconstruction with Self-Projection Optimization





## Abstract

​	点云的上采样任务旨在从稀疏点和不规则点集中获取密集和均匀点集。尽管深度学习模型已经取得了显著进展，但它们需要 G.T. 密度点集作为监督信息，该信息只能在合成对训练数据上进行训练，不适合在实际扫描的稀疏数据下进行训练。然而，从真实的扫描稀疏数据中获得用于训练的大规模成对的稀疏密集点集既昂贵又乏味。

​	为了解决此问题，我们提出了一个名为SPU-Net的自监督点云上采样网络，以捕获位于物体下表面上的点的固有上采样模式。具体来说，我们提出了一个从粗到细的重构框架，该框架包含两个主要组件：分别为**点特征提取**和**点特征扩展**。

​	在**点特征提取**中，我们将**自注意模块与图卷积网络（GCN）**集成在一起，以同时捕获局部区域内部和区域之间的上下文信息。在**点特征扩展**中，我们引入了一种可分级学习的折叠策略，以生成具有可学习2D网格的上采样点集。 此外，为了进一步优化生成的点集中的噪声点，我们提出了一种与均匀性和重构项相关联的新的自投影优化，以作为联合损失，以促进自我监督的点云上采样。 



## 1. Introduction

当前的深度点云上采样方法，例如PU-Net[38]，MPU[36]和PU-GAN [17]，已经在某些综合数据集（例如 **ShapeNet**[5]和 **Visionair**[1]）上取得了优异的结果。 但是，这些方法通常需要将**真实的密集点集**作为网络训练中的监督信息。而且，训练数据通常是通过从公共数据集[17、38] 上对合成CAD模型进行采样而构建的，这对于实际扫描的数据是不可用的。 由于没有成对的地面实密度点集，因此无法在诸如 **ScanNet**[6]和 **KITTI**[8]等真实扫描的数据集下训练上述方法。另外，当来自合成数据的数据分布与真实扫描的数据分布不匹配时，在合成数据上训练的上采样网络不能很好地推广到真实（稀疏）扫描。因此，提出一种不受监督信息约束且能够保持原始数据分布的自监督点云上采样方法是有希望的。



近来，已经提出了一些无监督的图像超分辨率方法[39、26]，并且在生成高分辨率图像方面取得了令人满意的性能。然而，由于点云的不规则和无序性质，将这样的图像超分辨率方法直接应用于无监督的点云上采样是不平凡的。 具体来说，在深度学习模型的无监督点云上采样中存在两个挑战。  

（1）**如何在没有密集点集监督的情况下建立有效的自我监督信息？** 先前的方法，例如PU-GAN [17]和L2G-AE [20]，首先会生成具有深层网络的密集点集，然后将密集点集**降采样**回稀疏点集，在该稀疏点集中通常会应用一些监督信息稀疏点集。但是，在无监督的上采样任务中没有对密集点集的直接监视，这使得很难捕获固有的上采样模式。为解决此问题，我们提出了一种从粗到精的重构框架，以制定自监督的点云上采样。具体来说，我们首先将输入块降采样为一些粗糙的色块，然后通过从每个粗糙色块中重建输入块本身来捕获固有的上采样模式。接下来，可以通过聚合多个精细补丁来获得密集补丁，所有精细补丁都遵循输入补丁的分布。

（2）**深层网络上采样的点云应该忠实地表示底层物体表面。**由于点云的不规则性质和从稀疏云生成密集点云的网络偏差，在生成上采样的密集点集时，不可避免地会在底层表面周围带来一些噪声点，尤其是对于无监督的上采样方法。因此，需要一些特定的损失函数来**约束生成点的空间分布**，包括均匀性和平坦度。为了解决这些挑战，我们提出了一种新颖的自投影优化方法，将底面周围的噪声点投影到表面本身，并将其与统一项和重建项相关联，以作为共同损失，以促进上采样点的生成。 通常，我们的贡献总结如下：

- 我们提出了一种自监督的点云上采样网络（SPU-Net），而无需监督3D G.T. 密集点云。  SPU-Net 从下采样的补丁中反复进行上采样，不受配对训练数据的限制，并且可以保留原始数据分布。
- 我们提出了一个从粗到精的重构框架，以捕获本地块内部固有的上采样模式，这提供了一种新颖的自我监督方式来学习对点云进行上采样。
- 为了在没有地面实密度点集的情况下限制生成点的分布，我们引入了一种新颖的自投影优化，该交互将生成点沿投影方向交互地投影到基础对象表面上。

为了评估SPU-Net的性能，我们采用了四种广泛使用的指标，以与各种合成和实时扫描数据集下的最新技术方法进行比较。实验结果表明，我们的自我监督方法取得了良好的性能，在定性和定量比较方面均与监督方法相当。



---

## 2. Related Work

**传统点云上采样方法** 

传统方法尝试了各种优化策略，以在不使用深度学习模型的情况下生成上采样的点云。 例如，Alexa等[4]通过计算 Voronoi 图并在此图的顶点处添加点来对采样点进行上采样。之后，已经证明了局部最优投影（LOP）算子[18，13]对于基于L1中位数的点重采样和曲面重构有效，特别是对于带有噪声和离群值的点集。此外，黄等[14]介绍了一种用于边缘感知点集重采样的渐进策略。

为了填补大的空洞并完成缺失的区域，Dpoints [34]开发了一种新的点表示形式。总的来说，所有这些方法都不是数据驱动的，它们很大程度上依赖于**形状先验**，例如法线估计和平滑曲面假设。



**基于深度学习的点云上采样方法**

近年来，深度神经网络在各种点云处理任务（包括形状分类[21、19、31]，对象检测[24、28]，语义场景分割[12、27]和点云完成[[  32，29]。 

在点云上采样领域，Yu等人[38]作为先驱者，首先提出了一种深度神经网络PU-Net来对点集进行升采样，该方法通过学习多级每点特征并通过多分支卷积扩展点集来处理补丁。后来，他们设计了另一个边缘感知点云上采样名为EC-Net [37]的网络通过最小化点到边的距离来实现点扩展。

Wang等[36]提出了一个多步渐进式上采样网络3PU，以进一步维护块细节。 

最近，李等人[17]提出了一个基于GAN的框架来生成高质量的上采样点集PU-GAN。现有方法已经可以在合成数据集下生成高质量的高采样点云。但是，这些监督方法需要地面实密度点云作为监督信息，不适用于实际扫描的数据。 

刘等[20]提出了一个名为L2G-AE的深度神经网络，它可以通过重构重叠的局部区域来进行无监督的点云上采样。但是，L2G-AE集中于通过局部到全局重建来捕获全局形状信息，这限制了网络捕获固有的上采样模式并生成高质量的上采样点集。 

相反，我们在粗到精的框架中提供了从降采样的补丁中提取出的新方法，这使我们能够以自我监督的方式生成高质量的升采样的点云。



**无监督的点云处理方法** 

近来，几种方法已经研究了用于点云分析的无监督学习策略。 自动编码器，例如 FoldingNet [35]和 L2G-AE [20]，是一种广泛用于无监督点云学习的框架，该框架采用输入点云本身作为重建目标。

在自我重构过程中，获得了相应的点特征，这些点特征可以应用于各种应用中，例如形状分类[35]，语义分割[10、11]和形状生成[10]。基于 AE 架构，一些工作进行了自监督的信息作为优化目标，例如坐标变换[7]，变形重构[2]和零件划分[40]。另外，生成对抗网络[3]也被用于区分生成的点集或真实的点集。在这项工作中，我们采用广义的 AE 框架来构建基于本地块的自监督式上采样网络。为了捕获**固有的上采样模式**，关键问题是如何在不需要监督的密集点集的情况下重现上采样过程。

为解决此问题，我们提出了一种从粗到细的重建框架，以重现本地块内部的点云上采样。 具体来说，我们首先将输入补丁降采样为几个子集，然后使用从粗到精的重构框架对子集进行升采样。 通过重复进行下采样和上采样步骤，我们的方法可以生成密集的上采样点集。



---

## 3. The Architecture of SPU-Net 

### 3.1. Overview

![1615298499078](assets/1615298499078.png)

**Fig. 2** The architecture of SPU-Net. 给定一个具有 N 个点的输入patch，我们首先将输入patch降采样为r个粗糙色块 $\mathcal{P}_j$，每个粗糙色块 $\mathcal{P}_j$ 具有 $N/r$ 个点，其中 $r$ 是上采样率。然后，我们在 coarse-to-ﬁne 的重构框架中为每个粗糙的 patch $\mathcal{P}_j$ 生成一个精细的patch  $\mathcal{Q}_j$，该框架包括点特征提取和扩展。最后，我们通过汇总所有精细的补丁来获得目标密集补丁 $\mathcal{T}$。 此外，在实现中，$C$ 和 $C'$ 分别是特征通道数480和128； $\mathcal{L}_{rec}$，$\mathcal{L}_{uni}$ 和 $\mathcal{L}_{sp}$ 分别表示重构项，均匀项和自投影项。



​	给定一个3D点云，我们采用与PU-Net[38]和PU-GAN[17]相同的基于patch的方法。我们首先根据3D点云的测地距离构建 $N_p$ 个局部patch，如图2所示。对于每个具有N个点的局部块 $\mathcal{S} = \left\{\boldsymbol{s}_{i}\right\}_{i = 1}^{N}$，我们的目标是输出一个**密集且均匀**的点在**保持原始数据分布**的同时，将 $ \mathcal{T}=\left\{\boldsymbol{t}_{i}\right\}_{i=1}^{r N} $ 设置为 $rN$ 个点，其中 $s_i$，$t_i$ 是3D 点的坐标，$r$ 是采样率。 在没有G.T. 密集点集的监督的情况下，我们提出了从粗到细的构造框架，以再现每个局部patch内的上采样过程。通过对稀疏样点进行上采样以获得细小patch，能够捕获固有的上样模式以生成均匀分布在物体下表面上的密集patch $\mathcal{T}$。

​	图2说明了我们的SPU-Net的体系结构。 对于输入块 $\mathcal{S}$ ，我们首先将 $\mathcal{S}$ 降采样为 $r$ 个不同的粗糙色块 $ \left\{\mathcal{P}_{1}, \cdots, \mathcal{P}_{j}, \cdots, \mathcal{P}_{r}\right\} $ ，每个都有 $N / r$个点（第3.2节）。 然后，我们引入从粗到细的框架来探索局部patch内部的固有采样模式（第3.3节），该模式包含两个主要组件：点特征提取和点特征扩展。 最后，我们提出了基于patch的训练策略，具有通过重建，均匀，自投影的术语形成的联合损失函数（第3.4节）。

---

### 3.2. Point Set Downsampling

​	在没有密集点集监督的情况下，我们必须构造一些**自我监督信息**来支持深层网络以捕获固有的上采样模式。为了在没有监督信息的情况下利用输入patch，我们提出了一种从粗到细的重构框架来生成上采样的密集补丁。具体来说，如图2所示，我们首先将输入色块 $S$ 降采样为一些粗糙的色块 $\mathcal{P}_j$，从而用输入patch本身来构成自我监督。下采样方法在很大程度上决定了深层网络捕获3D形状的表面分布的能力，这种能力应该保留输入patch的分布信息。这里，我们的方法采用了最远点采样（FPS）算法，该算法保留了patch**分布信息**，并且比其他抽样方法（例如随机抽样）保留了更**均匀**的粗糙patch。 具体来说，我们使用FPS算法重复从输入本地补丁中提取 $N / r$ 个点的过程。 最后，我们将降采样后的粗块表示为  $ \left\{\mathcal{P}_{1}, \cdots, \mathcal{P}_{j}, \cdots, \mathcal{P}_{r}\right\} $ 。 从下采样的粗补丁中，我们可以通过重构输入补丁本身来揭示固有的上采样过程，从而可以推断出更密集的补丁。



---

### 3.3. Coarse-to-Fine Reconstruction

​	在从粗到细的构造框架中，有两个主要组成部分：**点特征提取和点特征扩展**。 在点特征提取中，我们将**自注意力与图卷积网络（GCN）集成**在一起，以同时捕获局部区域内部和局部区域之间的点空间上下文。 在特征扩展方面，我们提出了一种**分层学习的折叠策略**，以方便从特征空间中的稀疏密度传播特征。

#### Point feature extraction

To capture the context information from discrete point sets, it is important to extract the spatial correlation of points inside local regions. The graph convolutional network (GCN) [25, 30, 21, 19] has been widely applied to capture the context information inside local regions in existing methods. However, these methods often ignore to capture the correlation among local regions. To simultaneously extract the context information both inside and among local regions, we propose a point feature extractionmodule,whichintegratesself-attentionunitswith GCNs, as shown in Figure 3.

为了从离散点集中捕获上下文信息，提取局部区域内点的空间相关性很重要。 图卷积网络（GCN）[25、30、21、19]已被广泛应用于在现有方法中捕获局部区域内的上下文信息。 但是，这些方法经常忽略捕获局部区域之间的相关性。 为了同时提取局部区域内部和局部区域之间的上下文信息，我们提出了一种点特征提取模块，该模块将自我注意单元与GCN集成在一起，如图3所示。

![1615299315535](assets/1615299315535.png)

**Fig. 3** The coarse-to-ﬁne reconstruction framework. 给定一个具有 $N / r$ 个点的粗糙补丁 $P_j$，我们旨在生成具有 $N$ 个点的相应的精细补丁 $Q_j$。在此框架中，有两个主要组件：点特征提取和点特征扩展。 在此，$D$ 和 $C$ 是实现中的特征通道数，分别为64和480。



​	给定一个大小为 $N / r×3$ 的粗糙patch $P_j$ 作为输入，通过在每个点 $p_j^i$ 周围构建局部图，尝试使用三个GCN捕获局部区域内的局部上下文。 我们介绍了具有多个语义级别的分层特征提取策略。 假设GCN在级别 $$ l \in\{0,1,2,3\} $$ 上的输入特征图为 $ \boldsymbol{F}^{l}=\left\{\boldsymbol{f}_{i}^{l}\right\}_{i=1}^{M} $ 且大小为 $M×C_d$ ，其中 $f_i^l$ 是 $F^l$ 内第 $i$ 个点特征。特别的，级别0的特征图 $F^0$ 是来自 $P_j$ 的原始点。为了计算点特征$f^{l + 1}_ i$，我们首先使用k-NN算法动态构建一个局部区域 $N^l_ i$，在每个点特征 $f_i^l$ 周围具有K个邻居。 然后，将点特征 $ \boldsymbol{f}_{i}^{l}(l \in\{0,1,2\}) $ 的传播计算为
$$
\boldsymbol{f}_{i}^{l+1}=\max _{\boldsymbol{f}_{j}^{l} \in \mathcal{N}_{i}^{l}}\left\{\sigma\left(\boldsymbol{h}_{\boldsymbol{\theta}}\left(\boldsymbol{f}_{j}^{l}-\boldsymbol{f}_{i}^{l}\right)\right\}\right. \tag{1}
$$
​	这里，$ \left(\boldsymbol{f}_{j}^{l}-\boldsymbol{f}_{i}^{l}\right) $ 可以看作是从点 $f^l_ j$ 到中心点 $f^l_ i$ 的边，$h_θ$ 表示多层感知器（MLP）中的可学习参数，$σ$ 是非线性层，例如ReLU, max是一个最大池化的操作符。最大池层被应用于局部区域 $N^l_i$ 中的聚合点特征。



​	根据先前的工作[20，17]，我们集成了自注意力单元来捕获局部区域之间的相关性。如图3所示，自我关注单元与GCN合作，以捕获局部patch内部的详细空间上下文信息。 假设输入特征图是 $\boldsymbol{F}^{l}$，大小为 $M×C_d$。 使用三个MLP将 $\boldsymbol{F}^{l}$ 分别嵌入到不同的特征空间 $X，Y$和 $H$ 中。 特别地，$X$ 和 $Y$ 被应用来通过简单的矩阵乘法来计算关注值，更新的特征图 $\hat{\boldsymbol{F}}^{l}$ 被计算为
$$
\hat{\boldsymbol{F}}^{l}=\boldsymbol{F}^{l}+\operatorname{softmax}\left(\boldsymbol{Y} \boldsymbol{X}^{\top}\right) \boldsymbol{H} \tag{2}
$$
​	在多个自我注意单元之后，局部区域之间的相关性以不同的语义级别被捕获。 然后，我们通过串联将多级点要素聚合为
$$
\overline{\boldsymbol{F}}=M L P\left(\boldsymbol{F}^{1} \oplus \hat{\boldsymbol{F}}^{1} \oplus \hat{\boldsymbol{F}}^{2} \oplus \hat{\boldsymbol{F}}^{3}\right) \tag{3}
$$
​	为了进一步探讨聚集特征 $\overline{\boldsymbol{F}}$ 的相关性，我们添加了另一个自我注意单元以获得最终的点特征 $F$。

----

#### Point feature expansion

点特征扩展的目标是构造从当前点到更多点的映射，这种映射在某些点应用中被广泛使用，例如语义分割[25]，点云重构[3]和点云上采样[17]。 通常，当前点特征扩展方法可以大致分为**基于插值**的方法[25]，**基于folding**的方法[35]和**基于reshape**的方法[3]。 现有的基于点插值的方法通常使用点插值关系来指导点特征的扩展。但是，在许多情况下，点集之间的插值关系通常是未知的。此外，基于重塑的方法通常首先使用诸如 MLP 或全连接（FC）层之类的深层网络扩展特征尺寸，然后通过简单的 reshape 操作生成目标点特征。近年来，已经开发出了基于 folding 的方法，该方法首先复制点特征，然后连接 2D 网格以指导点特征扩展。

与其他特征扩展方法相比，基于折叠的方法更加灵活，并且在各种应用中均取得了令人满意的性能[35，33]。 但是，先前固定的 2D grid 无法适应不同特征分布。为解决此问题，本文提出了新颖的可学习 2D grid 作为潜在编码，以与固定 2D grid 配合使用，以指导点要素扩展。 如图3所示，给定一个大小为 $M×C_d$ 的输入特征图，我们首先复制点特征，然后将两种网格连接起来。特别是，潜在代码是从标准正态分布初始化的，并且可以在网络训练过程中进行优化。此外，为了平滑点特征扩展过程，我们引入了分层折叠策略。 通过使用两个上采样块，我们获得了上采样的点特征 $\overline{\boldsymbol{F}}_{up}$ 和具有上采样率 $\sqrt{r}$ 的 $F_{up}$ 。 对于后续的MLP，将应用特征点  $F_{up}$ 来重建精细补丁。



---

### 3.4. Loss Function





---

## 4. Experiments







---

## 5. Conclusion

在本文中，我们提出了一种新的自监督点云上采样方法，该方法可从稀疏输入生成密集且均匀的点集，而无需监督G.T.密度点云。 我们的粗到细重构框架通过点特征提取和点特征扩展有效地促进了点向上采样。 另外，我们的自投影优化将噪声点成功地自身投影到基础对象表面上，从而以无人监督的方式极大地提高了点云上采样的质量。 我们的实验结果表明，我们的方法在合成数据集和实时扫描数据集上都可以实现良好的性能，甚至可以与最新的监督方法相媲美。







